{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Machine Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Collaborative Filtering (ALS)\n",
    "\n",
    "ALS is a model we are using to create predictions of restaurants, hotels or rent a cars based on the ratings from other users.\n",
    "\n",
    "This image shows an example of predicting of the user's rating using collaborative filtering. At first, people rate different items (like videos, images, games). After that, the system is making predictions about user's rating for an item, which the user hasn't rated yet. These predictions are built upon the existing ratings of other users, who have similar ratings with the active user. For instance, in our case the system has made a prediction, that the active user won't like the video.\n",
    "\n",
    "![alt text](../images/Collaborative_filtering.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import our SparkSession so we can use it\n",
    "from pyspark.sql import SparkSession, SQLContext, functions as F\n",
    "from pyspark.sql.functions import col, udf, regexp_replace\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "### Import machine learning libraries.\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "### Create our SparkSession, this can take a couple minutes locally\n",
    "spark = SparkSession.builder.appName(\"Review_data_JSON1\").config('spark.sql.broadcastTimeout','34000').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- cool: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Open the data from review.json\n",
    "df_reviews = spark.read.json(\"../data_source/review.json\")\n",
    "df_reviews.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Take only 192.000 rows from the original review.json.\n",
    "ratingsRDD = df_reviews.select(\"user_id\", \"business_id\", \"stars\").take(192000)\n",
    "\n",
    "df_reviews = spark.createDataFrame(ratingsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Check the schema of the DtaFrame.\n",
    "df_reviews.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------------------+\n",
      "|summary|             user_id|         business_id|             stars|\n",
      "+-------+--------------------+--------------------+------------------+\n",
      "|  count|              192000|              192000|            192000|\n",
      "|   mean|                null|                null|3.7318854166666666|\n",
      "| stddev|                null|                null|1.4569912639557216|\n",
      "|    min|---1lKK3aKOuomHnw...|--Gc998IMjLn8yr-H...|               1.0|\n",
      "|    max|zzrwygYbYs-NgFEe-...|zzwhN7x37nyjP0ZM8...|               5.0|\n",
      "+-------+--------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Shows the definition of the table.\n",
    "df_reviews.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+-------------+-----------------+\n",
      "|             user_id|         business_id|stars|user_id_index|business_id_index|\n",
      "+--------------------+--------------------+-----+-------------+-----------------+\n",
      "|hG7b0MtEbXx5QzbzE...|ujmEBvifdJM6h6RLv...|  1.0|      21237.0|            448.0|\n",
      "|yXQM5uF2jS6es16SJ...|NZnhc2sEQy3RmzKTZ...|  5.0|     131602.0|           1828.0|\n",
      "|n6-Gk65cPZL6Uz8qR...|WTqjgwHlXbSFevF32...|  5.0|      82215.0|           2691.0|\n",
      "|dacAIZ6fTM6mqwW5u...|ikCg8xy5JIg_NGPx-...|  5.0|      88932.0|           6871.0|\n",
      "|ssoyf2_x0EQMed6fg...|b1b1eb3uo-w561D0Z...|  1.0|      66574.0|           1725.0|\n",
      "|w31MKYsNFMrjhWxxA...|eU_713ec6fTGNO4Be...|  4.0|      33069.0|            859.0|\n",
      "|jlu4CztcSxrKx56ba...|3fw2X5bZYeW9xCz_z...|  3.0|       1079.0|           1344.0|\n",
      "|d6xvYpyzcfbF_AZ8v...|zvO-PJCpNk4fgAVUn...|  1.0|      21864.0|           4911.0|\n",
      "|sG_h0dIzTKWa3Q6fm...|b2jN2mm9Wf3RcrZCg...|  2.0|     113518.0|           2310.0|\n",
      "|nMeCE5-xsdleyxYuN...|oxwGyA17NL6c5t1Et...|  3.0|       5090.0|             92.0|\n",
      "|FIk4lQQu1eTe2EpzQ...|8mIrX_LrOnAqWsB5J...|  4.0|        128.0|             20.0|\n",
      "|-mA3-1mN4JIEkqOtd...|mRUVMJkUGxrByzMQ2...|  1.0|      99832.0|           2002.0|\n",
      "|GYNnVehQeXjty0xH7...|FxLfqxdYPA6Z85PFK...|  4.0|      81998.0|           3318.0|\n",
      "|bAhqAPoWaZYcyYi7b...|LUN6swQYa4xJKaM_U...|  4.0|      70503.0|            685.0|\n",
      "|TpyOT5E16YASd7EWj...|AakkkTuGZA2KBodKi...|  1.0|       4721.0|           2406.0|\n",
      "|NJlxGtouq06hhC7sS...|YvrylyuWgbP90RgMq...|  5.0|     122920.0|           1631.0|\n",
      "|86J5DwcFk4f4In1Vx...|NyLYY8q1-H3hfsTwu...|  4.0|     112106.0|             94.0|\n",
      "|JSrP-dUmLlwZiI7Dp...|cHdJXLlKNWixBXpDw...|  3.0|       3226.0|             15.0|\n",
      "|6Fz_nus_OG4gar721...|6lj2BJ4tJeu7db5as...|  5.0|      56548.0|           1172.0|\n",
      "|_N7Ndn29bpll_961o...|y-Iw6dZflNix4BdwI...|  3.0|      17085.0|            383.0|\n",
      "+--------------------+--------------------+-----+-------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_indexing = [\"user_id\", \"business_id\"]\n",
    "\n",
    "### Using StringIndexer to create a category feature for user_id and business_id.\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df_reviews) for column in columns_indexing]\n",
    "\n",
    "### Creating a Pipeline to index two columns from the current dataset.\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "\n",
    "### Creating the new DataFrame after encoding user and business Id's.\n",
    "df_reviews_prepro = pipeline.fit(df_reviews).transform(df_reviews)\n",
    "\n",
    "### Show results.\n",
    "df_reviews_prepro.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Spliting in training, validation and test datasets.\n",
    "(training_review, test_review) = df_reviews_prepro.select(\"user_id_index\",\"business_id_index\",\"stars\").randomSplit([0.8, 0.2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id_index: double (nullable = false)\n",
      " |-- business_id_index: double (nullable = false)\n",
      " |-- stars: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Validation and Test datasets should have 40% of the data each one.\n",
    "training_review.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Training data is expected as 20% of the total of records.\n",
    "test_review.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Creating our ALS prediction model.\n",
    "als_model = ALS(userCol=\"user_id_index\", \n",
    "                itemCol=\"business_id_index\", \n",
    "                ratingCol=\"stars\",\n",
    "                coldStartStrategy=\"drop\",\n",
    "                nonnegative = True\n",
    "               )\n",
    "\n",
    "# maxIter=5, regParam=0.01,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tuning model\n",
    "param_grid = ParamGridBuilder()\\\n",
    "            .addGrid(als_model.rank, [12, 13, 14])\\\n",
    "            .addGrid(als_model.maxIter, [18, 19, 20])\\\n",
    "            .addGrid(als_model.regParam, [.17, .18, .19])\\\n",
    "            .build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate as Root Mean Squared Error\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"stars\", predictionCol=\"prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "tvs = TrainValidationSplit(\n",
    "            estimator=als_model,\n",
    "            estimatorParamMaps=param_grid,\n",
    "            evaluator=evaluator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Training the model.\n",
    "model = tvs.fit(training_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALS_fb94b9294a15"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = model.bestModel\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id_index: double, business_id_index: double, stars: double, prediction: float]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = best_model.transform(test_review)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.720059351756456"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmes = evaluator.evaluate(predictions)\n",
    "rmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.720059351756456\n",
      "Rank: 14\n",
      "MaxInter: 20\n",
      "RMSE: 0.19\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: {}\".format(str(rmes)))\n",
    "print(\"Rank: {}\".format(best_model.rank))\n",
    "print(\"MaxInter: {}\".format(best_model._java_obj.parent().getMaxIter() ))\n",
    "print(\"RMSE: {}\".format(best_model._java_obj.parent().getRegParam() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+-----+----------+\n",
      "|user_id_index|business_id_index|stars|prediction|\n",
      "+-------------+-----------------+-----+----------+\n",
      "|       3744.0|            148.0|  4.0| 2.7375278|\n",
      "|        665.0|            148.0|  4.0|  4.125117|\n",
      "|        163.0|            148.0|  4.0| 3.1874242|\n",
      "|      15204.0|            148.0|  1.0| 1.4403815|\n",
      "|      19899.0|            148.0|  4.0| 3.0769997|\n",
      "|      13816.0|            148.0|  1.0| 3.8332148|\n",
      "|       1187.0|            148.0|  5.0| 3.8611677|\n",
      "|       7943.0|            148.0|  5.0| 3.7071636|\n",
      "|       1522.0|            463.0|  2.0| 3.1605837|\n",
      "|       3056.0|            463.0|  5.0| 2.7985938|\n",
      "|      19341.0|            463.0|  1.0| 1.8810831|\n",
      "|       1203.0|            463.0|  4.0| 2.2243347|\n",
      "|       9017.0|            463.0|  5.0| 1.1739373|\n",
      "|        950.0|            471.0|  5.0| 3.8654156|\n",
      "|      12442.0|            471.0|  5.0| 3.3523858|\n",
      "|       2741.0|            471.0|  5.0| 4.1526866|\n",
      "|       3066.0|            471.0|  4.0| 4.3686895|\n",
      "|       1239.0|            471.0|  5.0| 3.0525534|\n",
      "|      19386.0|            471.0|  5.0| 2.6479685|\n",
      "|       8132.0|            496.0|  5.0|  1.788928|\n",
      "+-------------+-----------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
